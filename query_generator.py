# query_generator.py ‚Äî version 100% LLM-driven intelligente
import os
import re
import gc
import json
import logging
import atexit
from pathlib import Path
from langchain_community.llms import LlamaCpp
from langchain.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("fraudlens-llm")

ROOT_DIR = Path(__file__).parent
MODEL_PATH = ROOT_DIR / "models" / "mistral-7b-instruct-v0.2.Q4_K_M.gguf"

if not MODEL_PATH.exists():
    raise FileNotFoundError(
        f"‚ùå Mod√®le non trouv√© √† {MODEL_PATH}\n"
        "T√©l√©chargez-le depuis : https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.2-GGUF"
    )

N_THREADS = max(1, (os.cpu_count() or 4) - 2)
_global_llm = None

def get_llm():
    """Renvoie le LLM global (charg√© une seule fois)"""
    global _global_llm
    if _global_llm is None:
        _global_llm = load_llm()
    return _global_llm


def load_llm():
    logger.info(f"üß† Chargement du mod√®le optimis√© Mistral depuis {MODEL_PATH}")
    llm = LlamaCpp(
        model_path=str(MODEL_PATH),
        n_ctx=1024,                # r√©duit le contexte ‚Üí moins de latence
        n_threads=os.cpu_count(),  # utilise tous les c≈ìurs CPU
        n_batch=128,               # petit batch = r√©ponse plus fluide
        n_gpu_layers=0,            # reste full CPU
        f16_kv=True,               # cl√©-valeurs en float16 (gain m√©moire et temps)
        temperature=0.1,
        top_p=0.9,
        verbose=False,
        use_mlock=False,           # √©vite les copies inutiles
        use_mmap=True,             # mmap = lecture directe sans chargement complet
        streaming=True,            # g√©n√®re token par token (r√©duit latence visible)
    )
    return llm


META_PROMPT = """
<|system|>
Tu es **Fraud-Lens Copilot**, un assistant intelligent sp√©cialis√© en analyse de fraude bancaire.
Tu comprends les questions en langage naturel et tu r√©ponds UNIQUEMENT en **JSON strictement valide**.

---

### üéØ TA MISSION
Analyser la question de l'utilisateur pour d√©terminer son intention :
1Ô∏è‚É£ **Intention "business"** ‚Üí question th√©orique ou explicative  
   (ex : "Explique ce qu‚Äôest une transaction frauduleuse", "Comment d√©tecter un compte compromis ?")  
   ‚ûú type = "business"  
   ‚ûú sql = ""  
   ‚ûú metric_name = ""  
   ‚ûú explanation = courte explication m√©tier claire et informative

2Ô∏è‚É£ **Intention "analytical"** ‚Üí question de calcul, agr√©gat ou statistique  
   (ex : "Combien de fraudes ?", "Quel est le taux de fraude ?")  
   ‚ûú type = "analytical"  
   ‚ûú g√©n√©rer une requ√™te SQL avec COUNT, SUM, AVG, etc.

3Ô∏è‚É£ **Intention "sql"** ‚Üí question demandant un √©chantillon de transactions  
   (ex : "Montre 5 transactions frauduleuses", "Liste les fraudes r√©centes")  
   ‚ûú type = "sql"  
   ‚ûú g√©n√©rer une requ√™te SQL avec SELECT ... LIMIT ...

---

### üß† DONN√âES DISPONIBLES
Base DuckDB avec table `transactions`
Champs : step, type, amount, oldbalanceOrg, newbalanceOrig, oldbalanceDest, newbalanceDest, isFraud  
Valeurs possibles de `type`: 'TRANSFER', 'CASH_OUT', 'CASH_IN', 'DEBIT', 'PAYMENT'  
`isFraud = 1` indique une fraude confirm√©e.

---

### üßÆ R√àGLES DE LOGIQUE
- Si la question commence par *combien*, *nombre*, *taux*, *moyenne*, *pourcentage* ‚Üí analytical  
- Si la question contient *montre*, *liste*, *donne-moi*, *affiche* ‚Üí sql  
- Si la question contient *explique*, *qu‚Äôest-ce que*, *comment d√©tecter*, *d√©finis* ‚Üí business  
- En cas de doute, prioriser **analytical** si la question mentionne des donn√©es concr√®tes (fraudes, montants, transferts, etc.)  

---

### üîç FORMAT DE SORTIE STRICT
R√©ponds UNIQUEMENT en JSON valide, sans aucun texte additionnel :
{{
  "type": "business" | "analytical" | "sql",
  "sql": "REQU√äTE SQL SI APPLICABLE (vide si type=business)",
  "metric_name": "Nom du m√©trique si applicable",
  "explanation": "Phrase claire et concise expliquant le sens de la r√©ponse"
}}

---

### ‚úÖ EXEMPLES

Question : "Combien de fraudes dans les transferts ?"
R√©ponse :
{{
  "type": "analytical",
  "sql": "SELECT COUNT(*) FROM transactions WHERE isFraud = 1 AND type = 'TRANSFER';",
  "metric_name": "Fraudes TRANSFER",
  "explanation": "Nombre total de fraudes d√©tect√©es dans les transactions de type TRANSFER."
}}

Question : "Explique ce qu‚Äôest une transaction frauduleuse"
R√©ponse :
{{
  "type": "business",
  "sql": "",
  "metric_name": "",
  "explanation": "Une transaction frauduleuse est une op√©ration non autoris√©e effectu√©e par un individu malveillant pour d√©tourner de l‚Äôargent sans le consentement du titulaire du compte."
}}

Question : "Montre 5 transactions frauduleuses"
R√©ponse :
{{
  "type": "sql",
  "sql": "SELECT * FROM transactions WHERE isFraud = 1 ORDER BY step DESC LIMIT 5;",
  "metric_name": "Exemples de fraudes",
  "explanation": "Les 5 transactions les plus r√©centes identifi√©es comme frauduleuses."
}}

---

<|user|>
{query}
<|assistant|>
"""


# ---- process_query (remplace la version existante) ----
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
import json
import re
import logging

logger = logging.getLogger("fraudlens-llm")

def process_query(query: str, llm_instance):
    """Interpr√©tation compl√®te de la requ√™te par le LLM"""
    chain = (
        PromptTemplate(template=META_PROMPT, input_variables=["query"])
        | llm_instance
        | StrOutputParser()
    )

    raw_output = chain.invoke({"query": query}).strip()
    logger.info(f"üß† Sortie brute du mod√®le : {raw_output}")

    # üîç Recherche d‚Äôun JSON dans la sortie
    json_match = re.search(r"\{[\s\S]*\}", raw_output)
    json_text = json_match.group(0) if json_match else None
    result = None

    # üß© √âtape 1 : Parsing JSON (si trouv√©)
    if json_text:
        try:
            result = json.loads(json_text)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è JSON mal form√© : {e}")

    # üß© √âtape 2 : Si pas de JSON ‚Üí encapsuler texte
    if not result and len(raw_output.split()) > 3:
        logger.info("‚úÖ Encapsulation automatique de la sortie texte en JSON business")
        result = {
            "type": "business",
            "sql": "",
            "metric_name": "",
            "explanation": raw_output.strip()
        }

    # üß© √âtape 3 : Fallback ultime
    if not result:
        logger.warning(f"‚ö†Ô∏è Sortie non JSON du mod√®le : {raw_output}")
        result = {
            "type": "business",
            "sql": "",
            "metric_name": "",
            "explanation": get_fallback_explanation(query),
        }

    # üß© √âtape 4 : Correction automatique du SQL si besoin
    sql_text = result.get("sql", "")
    if sql_text:
        fixed_sql = sanitize_sql(sql_text)
        if fixed_sql != sql_text:
            logger.info(f"üõ† SQL corrig√© automatiquement : {fixed_sql}")
        result["sql"] = fixed_sql

        # V√©rifie les parenth√®ses
        if fixed_sql.count("(") != fixed_sql.count(")"):
            logger.warning(f"‚ö†Ô∏è SQL potentiellement invalide : {fixed_sql}")
            try:
                correction_prompt = f"""
Corrige cette requ√™te SQL DuckDB pour qu‚Äôelle soit valide :
{sql_text}
R√©ponds UNIQUEMENT avec la requ√™te corrig√©e (pas de texte, pas de JSON).
"""
                corrected = llm_instance.invoke(correction_prompt).strip()
                if corrected.startswith("SELECT"):
                    logger.info(f"‚úÖ SQL r√©par√© par le LLM : {corrected}")
                    result["sql"] = corrected
            except Exception as e:
                logger.error(f"üí• Erreur correction SQL par LLM : {e}")

    return result
def sanitize_sql(sql: str) -> str:
    """Nettoyage l√©ger du SQL pour corriger les erreurs courantes du LLM"""
    sql = sql.strip()
    # Supprimer les doubles parenth√®ses ou caract√®res parasites
    sql = re.sub(r"\)\)", ")", sql)
    sql = re.sub(r"\(\(", "(", sql)
    sql = re.sub(r";+", ";", sql)
    # Corriger les alias mal √©crits
    sql = re.sub(r"\s+as\s+", " AS ", sql, flags=re.IGNORECASE)
    # Corriger AVG(isFraud)) -> AVG(isFraud)
    sql = sql.replace("))", ")")
    return sql

def get_fallback_explanation(query: str) -> str:
    """R√©ponse de secours si le mod√®le √©choue"""
    q = query.lower()
    if "taux" in q:
        return "Le taux de fraude = (nombre de fraudes / total des transactions) * 100."
    elif "fraude" in q:
        return (
            "Une transaction frauduleuse correspond √† une op√©ration non autoris√©e, souvent li√©e √† des transferts anormaux."
        )
    return "Je suis un assistant d'analyse de fraude bancaire. Posez-moi une question comme 'Combien de fraudes ?'."


def _safe_close_llm(llm):
    try:
        if hasattr(llm, "_model") and hasattr(llm._model, "close"):
            llm._model.close()
        gc.collect()
    except Exception as e:
        logger.error(f"Erreur fermeture mod√®le : {e}")


atexit.register(lambda: _safe_close_llm(globals().get("_global_llm", None)))


if __name__ == "__main__":
    llm = load_llm()
    q = "Combien de fraudes dans les transferts ?"
    print(json.dumps(process_query(q, llm), indent=2, ensure_ascii=False))
    _safe_close_llm(llm)
